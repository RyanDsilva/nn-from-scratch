# Neural Networks From Scratch

ðŸŒŸ Implementation of Neural Networks from Scratch Using Python &amp; Numpy ðŸŒŸ

> Uses Python 3.7.4

## Optimizer Functions

Optimizer Functions help us update the parameters in the most efficient way possible. Optimizers update the weight parameters and bias terms to minimize the loss function to achieve global minimum.

- Gradient Descent

  <img src="images/gd.svg">

  `W: weights | dW: weights gradient (obtained from loss function) | alpha: learning rate`

- Gradient Descent with Momentum

  <img src="images/momentum.svg">

- RMSProp

  <img src="images/rms_prop.svg" />

- Adam

  <img src="images/adam.svg" />
